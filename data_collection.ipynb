{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "918b6a37",
   "metadata": {},
   "source": [
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45f36d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "\n",
    "# Third-party libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc0f48",
   "metadata": {},
   "source": [
    "## Fetching Data from BMRS Elexon Data\n",
    "1st Oct 2022 to 31st Dec 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "925ae00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_in_chunks(start_date, end_date, chunk_days, fetch_function):\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        next_date = min(current_date + timedelta(days=chunk_days - 1), end_date)\n",
    "        fetch_function(current_date.strftime('%Y-%m-%d'), next_date.strftime('%Y-%m-%d'))\n",
    "        current_date = next_date + timedelta(days=1)\n",
    "\n",
    "def fetch_csv_data(api_url, params, save_file, sort_by=None, parse_dates=None, headers=None):\n",
    "    response = requests.get(api_url, params=params, headers=headers or {})\n",
    "    if response.status_code != 200:\n",
    "        print(f\"[ERROR] Failed fetch: {response.status_code} | URL: {api_url}\")\n",
    "        return\n",
    "\n",
    "    df_new = pd.read_csv(StringIO(response.text), parse_dates=parse_dates)\n",
    "    if df_new.empty:\n",
    "        print(\"[INFO] No new data returned.\")\n",
    "        return\n",
    "\n",
    "    if os.path.exists(save_file):\n",
    "        df_existing = pd.read_csv(save_file, parse_dates=parse_dates)\n",
    "        df_combined = pd.concat([df_existing, df_new]).drop_duplicates()\n",
    "    else:\n",
    "        df_combined = df_new\n",
    "\n",
    "    if sort_by:\n",
    "        df_combined = df_combined.sort_values(by=sort_by)\n",
    "\n",
    "    df_combined.to_csv(save_file, index=False)\n",
    "    print(f\"[SUCCESS] Data saved to {save_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3fc7a8",
   "metadata": {},
   "source": [
    "Wind and Solar Day Ahead Forecast Data\n",
    "\n",
    "Wind and Solar Actual Generation Data\n",
    "\n",
    "Wind Generation Forecast Data \n",
    "\n",
    "Demand Forecast Data \n",
    "\n",
    "Temperature Data\n",
    "\n",
    "Great Britain Electricity Market Index Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "acfbd9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FETCH_CONFIGS = {\n",
    "    \"wind_solar_dayahead_forecast\": {\n",
    "        \"api_url\": \"https://data.elexon.co.uk/bmrs/api/v1/forecast/generation/wind-and-solar/day-ahead\",\n",
    "        \"params\": lambda start, end: {\n",
    "            \"from\": start,\n",
    "            \"to\": end,\n",
    "            \"settlementPeriodFrom\": 48,\n",
    "            \"settlementPeriodTo\": 0,\n",
    "            \"processType\": \"intraday process\",\n",
    "            \"format\": \"csv\"\n",
    "        },\n",
    "        \"save_file\": \"data/wind_solar_dayahead_forecast.csv\",\n",
    "        \"chunk_days\": 7\n",
    "    },\n",
    "    \"wind_solar_actual_generation\": {\n",
    "        \"api_url\": \"https://data.elexon.co.uk/bmrs/api/v1/generation/actual/per-type/wind-and-solar\",\n",
    "        \"params\": lambda start, end: {\n",
    "            \"from\": start,\n",
    "            \"to\": end,\n",
    "            \"settlementPeriodFrom\": 48,\n",
    "            \"settlementPeriodTo\": 1,\n",
    "            \"format\": \"csv\"\n",
    "        },\n",
    "        \"save_file\": \"data/wind_solar_actual_generation.csv\",\n",
    "        \"chunk_days\": 7\n",
    "    },\n",
    "    \"wind_forecast_winfor\": {\n",
    "        \"api_url\": \"https://data.elexon.co.uk/bmrs/api/v1/datasets/WINDFOR\",\n",
    "        \"params\": lambda start, end: {\n",
    "            \"publishDateTimeFrom\": start,\n",
    "            \"publishDateTimeTo\": end,\n",
    "            \"format\": \"csv\"\n",
    "        },\n",
    "        \"save_file\": \"data/wind_generation_forecast.csv\",\n",
    "        \"chunk_days\": 7\n",
    "    },\n",
    "    \"dayahead_demand_forecast\": {\n",
    "        \"api_url\": \"https://data.elexon.co.uk/bmrs/api/v1/forecast/demand/day-ahead/history\",\n",
    "        \"params\": lambda date, _: {\n",
    "            \"publishTime\": date,\n",
    "            \"format\": \"csv\"\n",
    "        },\n",
    "        \"save_file\": \"data/dayahead_demand_forecast.csv\",\n",
    "        \"chunk_days\": 1\n",
    "    },\n",
    "    \"temperature_data\": {\n",
    "        \"api_url\": \"https://data.elexon.co.uk/bmrs/api/v1/datasets/TEMP\",\n",
    "        \"params\": lambda start, end: {\n",
    "            \"publishDateTimeFrom\": f\"{start}T00:00:00Z\",\n",
    "            \"publishDateTimeTo\": f\"{end}T23:59:59Z\",\n",
    "            \"format\": \"csv\"\n",
    "        },\n",
    "        \"save_file\": \"data/temperature_data.csv\",\n",
    "        \"chunk_days\": None,  \n",
    "        \"chunk_type\": \"monthly\",\n",
    "        \"headers\": {\n",
    "            \"accept\": \"text/plain\"\n",
    "        }\n",
    "    },\n",
    "    \"market_index_prices\": {\n",
    "        \"api_url\": \"https://data.elexon.co.uk/bmrs/api/v1/balancing/pricing/market-index\",\n",
    "        \"params\": lambda start, end: {\n",
    "            \"from\": start,\n",
    "            \"to\": end,\n",
    "            \"settlementPeriodFrom\": 1,\n",
    "            \"settlementPeriodTo\": 50,\n",
    "            \"dataProviders\": \"APXMIDP\",\n",
    "            \"format\": \"csv\"\n",
    "        },\n",
    "        \"save_file\": \"data/market_index_prices.csv\",\n",
    "        \"chunk_days\": 7\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b77e96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_fetch(name, start_date, end_date):\n",
    "    config = FETCH_CONFIGS[name]\n",
    "    chunk_type = config.get(\"chunk_type\", \"days\")  # default to daily chunking\n",
    "    chunk_days = config.get(\"chunk_days\")\n",
    "    headers = config.get(\"headers\", {})\n",
    "\n",
    "    def fetch_callback(start, end):\n",
    "        params = config[\"params\"](start, end)\n",
    "        fetch_csv_data(\n",
    "            api_url=config[\"api_url\"],\n",
    "            params=params,\n",
    "            save_file=config[\"save_file\"],\n",
    "            headers=headers\n",
    "        )\n",
    "\n",
    "    if chunk_type == \"monthly\":\n",
    "        current = start_date\n",
    "        while current <= end_date:\n",
    "            next_month = (current.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
    "            batch_end = min(next_month, end_date)\n",
    "            fetch_callback(current.strftime('%Y-%m-%d'), batch_end.strftime('%Y-%m-%d'))\n",
    "            current = batch_end + timedelta(days=1)\n",
    "    else:\n",
    "        fetch_in_chunks(start_date, end_date, chunk_days, fetch_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5deffae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = datetime(2022, 10, 1)\n",
    "END_DATE = datetime(2024, 12, 31)\n",
    "\n",
    "# for dataset_name in FETCH_CONFIGS:\n",
    "#     print(f\"Fetching: {dataset_name}\")\n",
    "#     generic_fetch(dataset_name, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05698808",
   "metadata": {},
   "source": [
    "Possible Reasons for Missing Market Price Data\n",
    " \n",
    "- Looking at the missing periods:\n",
    "  - 2022-10-29 to 2022-11-04\n",
    "  - 2023-10-28 to 2023-11-03\n",
    "  - 2024-10-26 to 2024-11-01\n",
    "- These dates consistently fall at the end of October and the beginning of November each year.\n",
    "- Potential Cause: Daylight Saving Time (DST) Changes\n",
    "    - Many countries, including the UK and parts of Europe, switch from DST to Standard Time on the last weekend of October. This transition could lead to gaps or shifts in settlement period reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b567ed0",
   "metadata": {},
   "source": [
    "# Compiling Master Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b459f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_start = pd.Timestamp(\"2022-10-01\")\n",
    "expected_end = pd.Timestamp(\"2024-12-31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc4bdd",
   "metadata": {},
   "source": [
    "Market Index Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "21c27d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/market_index_prices.csv\")\n",
    "df['SettlementDate'] = pd.to_datetime(df['SettlementDate'])\n",
    "df_sorted = df.sort_values(by=['SettlementDate', 'SettlementPeriod'])\n",
    "\n",
    "# Create a DataFrame of all possible settlement dates and periods\n",
    "all_dates = pd.date_range(start=expected_start, end=expected_end)\n",
    "all_periods = range(1, 49) \n",
    "\n",
    "# Generate a full DataFrame of all possible combinations\n",
    "full_index = pd.MultiIndex.from_product([all_dates, all_periods], names=[\"SettlementDate\", \"SettlementPeriod\"])\n",
    "full_df = pd.DataFrame(index=full_index).reset_index()\n",
    "\n",
    "# Merge with the existing data, filling missing values with mean of 3 previous periods\n",
    "df_filled = full_df.merge(df_sorted, on=[\"SettlementDate\", \"SettlementPeriod\"], how=\"left\")\n",
    "df_filled[\"Price\"] = df_filled[\"Price\"].fillna(df_filled[\"Price\"].rolling(3, min_periods=1).mean())\n",
    "df_filled[\"Volume\"] = df_filled[\"Volume\"].fillna(df_filled[\"Volume\"].rolling(3, min_periods=1).mean())\n",
    "df_filled[\"StartTime\"] = pd.to_datetime(df_filled[\"StartTime\"], errors=\"coerce\")\n",
    "\n",
    "price_df = df_filled\n",
    "price_df.drop(columns=['DataProvider','StartTime'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e1ca5",
   "metadata": {},
   "source": [
    "Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e72ee1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_df = pd.read_csv(\"data/temperature_data.csv\")\n",
    "temperature_df[\"MeasurementDate\"] = pd.to_datetime(temperature_df[\"MeasurementDate\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Create a full range of Settlement Periods (1 to 48) for each MeasurementDate\n",
    "temperature_expanded = temperature_df.copy()\n",
    "temperature_expanded = temperature_expanded.loc[temperature_expanded.index.repeat(48)]\n",
    "temperature_expanded[\"SettlementPeriod\"] = list(range(1, 49)) * len(temperature_df)\n",
    "\n",
    "# Merge with the existing half-hourly market index dataset\n",
    "df_merged = price_df.merge(\n",
    "    temperature_expanded,\n",
    "    left_on=[\"SettlementDate\", \"SettlementPeriod\"],\n",
    "    right_on=[\"MeasurementDate\", \"SettlementPeriod\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "df_merged.drop(columns=[\"MeasurementDate\"], inplace=True)\n",
    "\n",
    "# Interpolate temperature values across the day for smoother transitions\n",
    "df_merged[\"Temperature\"] = df_merged.groupby(\"SettlementDate\")[\"Temperature\"].transform(lambda x: x.interpolate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ba27c",
   "metadata": {},
   "source": [
    "Wind Forecast Intraday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "03059321",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_forecast_df = pd.read_csv(\"data/wind_generation_forecast.csv\")\n",
    "wind_forecast_df['StartTime'] = pd.to_datetime(wind_forecast_df['StartTime'], utc=True)\n",
    "wind_forecast_df = wind_forecast_df.drop_duplicates(subset=['StartTime'])\n",
    "\n",
    "# Create a complete hourly index from 1st Oct 2022 to 31st Dec 2024 in UTC\n",
    "full_wind_index = pd.date_range(start='2022-10-01 00:00:00', end='2024-12-31 23:30:00', freq='h', tz='UTC')\n",
    "full_wind_df = pd.DataFrame(full_wind_index, columns=['StartTime'])\n",
    "full_wind_df = full_wind_df.merge(wind_forecast_df, on='StartTime', how='left')\n",
    "\n",
    "# Fill missing values for all columns using forward fill, then backfill as a fallback\n",
    "full_wind_df.ffill(inplace=True)\n",
    "full_wind_df.bfill(inplace=True)\n",
    "\n",
    "# Convert hourly data to half-hourly\n",
    "half_hourly_wind_index = pd.date_range(start='2022-10-01 00:00:00', end='2024-12-31 23:30:00', freq='min', tz='UTC')[::30]\n",
    "half_hourly_wind_df = pd.DataFrame(half_hourly_wind_index, columns=['StartTime'])\n",
    "half_hourly_wind_df = half_hourly_wind_df.merge(full_wind_df, on='StartTime', how='left')\n",
    "half_hourly_wind_df['Generation'] = half_hourly_wind_df['Generation'].interpolate(method='linear')\n",
    "half_hourly_wind_df[['Dataset', 'PublishTime']] = half_hourly_wind_df[['Dataset', 'PublishTime']].ffill().bfill()\n",
    "half_hourly_wind_df['SettlementPeriod'] = (half_hourly_wind_df['StartTime'].dt.hour * 2) + (half_hourly_wind_df['StartTime'].dt.minute // 30) + 1\n",
    "half_hourly_wind_df.sort_values(by='StartTime', inplace=True)\n",
    "\n",
    "wind_forecast=half_hourly_wind_df.drop(columns=['Dataset','PublishTime'])\n",
    "# wind_forecast.to_csv('processed_wind_forecast.csv', index=False)\n",
    "\n",
    "# Merge with the merged dataframe\n",
    "wind_forecast[\"SettlementDate\"] = pd.to_datetime(wind_forecast[\"StartTime\"].dt.date)\n",
    "df_merged[\"SettlementDate\"] = pd.to_datetime(df_merged[\"SettlementDate\"])\n",
    "\n",
    "# Ensure SettlementPeriod is integer in both datasets\n",
    "df_merged[\"SettlementPeriod\"] = df_merged[\"SettlementPeriod\"].astype(int)\n",
    "wind_forecast[\"SettlementPeriod\"] = wind_forecast[\"SettlementPeriod\"].astype(int)\n",
    "wind_forecast.drop(columns=[\"PublishTime\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Merge datasets on SettlementDate and SettlementPeriod\n",
    "df_merged = df_merged.merge(\n",
    "    wind_forecast,\n",
    "    on=[\"SettlementDate\", \"SettlementPeriod\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "df_merged[\"Time\"] = df_merged[\"SettlementPeriod\"].apply(\n",
    "    lambda x: f\"{(x-1)//2:02d}:{'30' if x % 2 == 0 else '00'}\"\n",
    ")\n",
    "df_merged.sort_values(by=[\"SettlementDate\", \"SettlementPeriod\"], inplace=True)\n",
    "df_merged.drop(columns=['StartTime','PublishTime'],inplace=True)\n",
    "df_merged = df_merged.rename(columns={'Generation': 'Wind Forecast IntraDay'})\n",
    "# df_merged.to_csv('final_merged_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee8c05",
   "metadata": {},
   "source": [
    "Day Ahead Demand Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9afa792",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_forecast_df = pd.read_csv(\"data/dayahead_demand_forecast.csv\")\n",
    "demand_forecast_df[\"SettlementDate\"] = pd.to_datetime(df[\"SettlementDate\"], errors=\"coerce\", dayfirst=True)\n",
    "demand_forecast_df[\"SettlementDate\"] = pd.to_datetime(demand_forecast_df[\"SettlementDate\"], errors='coerce')\n",
    "\n",
    "df_merged[\"SettlementDate\"] = pd.to_datetime(df_merged[\"SettlementDate\"], errors='coerce')\n",
    "full_settlement_periods = df_merged[[\"SettlementDate\", \"SettlementPeriod\"]].drop_duplicates()\n",
    "\n",
    "# Merge to identify missing periods in demand_forecast_df\n",
    "missing_periods = full_settlement_periods.merge(\n",
    "    demand_forecast_df, on=[\"SettlementDate\", \"SettlementPeriod\"], how=\"left\")\n",
    "missing_rows = missing_periods[missing_periods[\"TransmissionSystemDemand\"].isna()].drop(columns=[\"TransmissionSystemDemand\", \"NationalDemand\"])\n",
    "\n",
    "# Backfill missing demand values by merging with the existing demand data and using forward fill\n",
    "demand_forecast_complete = pd.concat([demand_forecast_df, missing_rows]).sort_values(\n",
    "    [\"SettlementDate\", \"SettlementPeriod\"]\n",
    ")\n",
    "\n",
    "demand_forecast_complete[\"TransmissionSystemDemand\"] = demand_forecast_complete[\"TransmissionSystemDemand\"].fillna(method=\"bfill\")\n",
    "demand_forecast_complete[\"NationalDemand\"] = demand_forecast_complete[\"NationalDemand\"].fillna(method=\"bfill\")\n",
    "\n",
    "# Perform the merge again with the corrected demand forecast data\n",
    "df_merged = df_merged.merge(\n",
    "    demand_forecast_complete, on=[\"SettlementDate\", \"SettlementPeriod\"], how=\"inner\")\n",
    "df_merged = df_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d9d78",
   "metadata": {},
   "source": [
    "Wind & Solar Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82a55bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_solar_df = pd.read_csv(\"data/wind_solar_actual_generation.csv\")\n",
    "wind_solar_df[\"SettlementDate\"] = pd.to_datetime(wind_solar_df[\"SettlementDate\"], errors='coerce')\n",
    "\n",
    "# Aggregate data by SettlementDate and SettlementPeriod\n",
    "wind_solar_aggregated = wind_solar_df.pivot_table(\n",
    "    index=[\"SettlementDate\", \"SettlementPeriod\"],\n",
    "    columns=\"PsrType\",\n",
    "    values=\"Quantity\",\n",
    "    aggfunc=\"sum\"\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "wind_solar_aggregated.columns.name = None  # Remove hierarchical column name\n",
    "wind_solar_aggregated = wind_solar_aggregated.rename(columns={\n",
    "    \"Wind Onshore\": \"Wind_Onshore_Generation\",\n",
    "    \"Wind Offshore\": \"Wind_Offshore_Generation\",\n",
    "    \"Solar\": \"Solar_Generation\"\n",
    "})\n",
    "wind_solar_aggregated = wind_solar_aggregated.fillna(0)\n",
    "\n",
    "# Merge with the existing merged dataset\n",
    "df_merged = df_merged.merge(\n",
    "    wind_solar_aggregated, on=[\"SettlementDate\", \"SettlementPeriod\"], how=\"left\"\n",
    ")\n",
    "df_merged = df_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4e5f3",
   "metadata": {},
   "source": [
    "NIV Data\n",
    "  - Loaded manually as the API doesn't work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b2b06e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "niv_df = pd.read_csv(\"data/NIV.csv\")\n",
    "niv_df[\"SettlementDate\"] = pd.to_datetime(niv_df[\"SettlementDate\"], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "\n",
    "# Identify missing periods compared to the merged dataset\n",
    "full_settlement_periods = df_merged[[\"SettlementDate\", \"SettlementPeriod\"]].drop_duplicates()\n",
    "missing_niv_periods = full_settlement_periods.merge(niv_df, on=[\"SettlementDate\", \"SettlementPeriod\"], how=\"left\")\n",
    "missing_niv_rows = missing_niv_periods[missing_niv_periods[\"NetImbalanceVolume\"].isna()].drop(columns=[\"NetImbalanceVolume\"])\n",
    "\n",
    "# Backfill missing NIV values using forward fill method\n",
    "niv_complete = pd.concat([niv_df, missing_niv_rows]).sort_values([\"SettlementDate\", \"SettlementPeriod\"])\n",
    "niv_complete[\"NetImbalanceVolume\"] = niv_complete[\"NetImbalanceVolume\"].fillna(method=\"bfill\")\n",
    "\n",
    "# Merge with the existing merged dataset\n",
    "df_merged = df_merged.merge(\n",
    "    niv_complete, on=[\"SettlementDate\", \"SettlementPeriod\"], how=\"left\"\n",
    ")\n",
    "df_merged = df_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b3646",
   "metadata": {},
   "source": [
    "Rolling System Demand\n",
    "  - Loaded manually as the API doesn't work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "569d4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_demand_df = pd.read_csv(\"data/demand_outturn_half_hourly_2022_2024_1.csv\")\n",
    "rolling_demand_df[\"StartTime\"] = pd.to_datetime(rolling_demand_df[\"StartTime\"], errors=\"coerce\")\n",
    "rolling_demand_df[\"SettlementDate\"] = rolling_demand_df[\"StartTime\"].dt.date\n",
    "rolling_demand_df[\"SettlementDate\"] = pd.to_datetime(rolling_demand_df[\"SettlementDate\"])\n",
    "\n",
    "# Ensure that all required settlement periods are present\n",
    "full_settlement_periods = df_merged[[\"SettlementDate\", \"SettlementPeriod\"]].drop_duplicates()\n",
    "missing_demand_periods = full_settlement_periods.merge(\n",
    "    rolling_demand_df, on=[\"SettlementDate\", \"SettlementPeriod\"], how=\"left\"\n",
    ")\n",
    "missing_demand_rows = missing_demand_periods[missing_demand_periods[\"Demand\"].isna()].drop(columns=[\"Demand\"])\n",
    "rolling_demand_complete = pd.concat([rolling_demand_df, missing_demand_rows]).sort_values(\n",
    "    [\"SettlementDate\", \"SettlementPeriod\"]\n",
    ")\n",
    "rolling_demand_complete[\"Demand\"] = rolling_demand_complete[\"Demand\"].fillna(method=\"bfill\")\n",
    "\n",
    "# Merge with the existing final dataset\n",
    "df_merged = df_merged.merge(\n",
    "    rolling_demand_complete, on=[\"SettlementDate\", \"SettlementPeriod\"], how=\"left\"\n",
    ")\n",
    "df_merged = df_merged.fillna(0)\n",
    "df_merged = df_merged.rename(columns={'Demand': 'Rolling_System_Demand'})\n",
    "df_merged.columns = [col.replace(' ', '_') for col in df_merged.columns]\n",
    "df_merged.drop(columns = ['StartTime_x','StartTime_y'], inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca6d74",
   "metadata": {},
   "source": [
    "FINAL DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d97d1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop original SettlementDate and Time columns\n",
    "df_merged[\"Datetime\"] = pd.to_datetime(df_merged[\"SettlementDate\"].astype(str) + \" \" + df_merged[\"Time\"])\n",
    "df_merged.drop(columns=[\"SettlementDate\", \"Time\"], inplace=True)\n",
    "\n",
    "# Reorder columns for better readability (Datetime first)\n",
    "cols = [\"Datetime\"] + [col for col in df_merged.columns if col != \"Datetime\"]\n",
    "df_merged = df_merged[cols]\n",
    "df_merged.to_csv(\"data/final_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
